{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "id": "2b118a9b-dab8-47f8-bb5e-be6116c51893",
      "metadata": {
        "language": "python"
      },
      "source": "import requests\nimport pandas as pd\nimport os\nimport json\nfrom datetime import datetime\nfrom requests.auth import HTTPBasicAuth\nfrom dotenv import load_dotenv\n\n# --- LOAD ENV FILE ---\nload_dotenv()\n\n# --- SNOWFLAKE IMPORTS ---\nimport snowflake.connector\nfrom snowflake.connector.pandas_tools import write_pandas\n\n# --- CONFIGURATION ---\nAPI_USER = os.getenv('RATER8_USER', '$UpperlineHealth')\nAPI_PASS = os.getenv('RATER8_PASS', 'Inept#crater$5') \nBASE_URL = \"https://rapi.rater8.com/api\"\n\n# FULL YEAR 2025 WINDOW\nFROM_DATE = \"2025-12-31\" \nTO_DATE = \"2026-01-09\"\n\nauth = HTTPBasicAuth(API_USER, API_PASS)\n\n# Snowflake Config\nSF_USER = os.getenv('SNOWFLAKE_USER')\nSF_PASSWORD = os.getenv('SNOWFLAKE_PASSWORD')\nSF_ACCOUNT = os.getenv('SNOWFLAKE_ACCOUNT')\nSF_WAREHOUSE = os.getenv('SNOWFLAKE_WAREHOUSE')\nSF_DATABASE = os.getenv('SNOWFLAKE_DATABASE')\nSF_SCHEMA = os.getenv('SNOWFLAKE_SCHEMA')\nSF_ROLE = os.getenv('SNOWFLAKE_ROLE')\n\n# DEBUGGING\nDEBUG_PRINT_RAW_JSON = True \nCUSTOM_Q_NPS_ID = -1 \n\n# --- UTILITY: API Fetcher ---\ndef get_permissions():\n    url = f\"{BASE_URL}/permissions\"\n    response = requests.get(url, auth=auth)\n    response.raise_for_status()\n    return response.json()\n\ndef build_client_code_lookup(permissions):\n    lookup = {}\n    for practice in permissions:\n        practice_id = practice.get('id')\n        practice_codes = \", \".join(map(str, practice.get('clientCodes', [])))\n        if practice_id:\n            lookup[f\"P_{practice_id}\"] = practice_codes\n        for employee in practice.get('employees', []):\n            employee_id = employee.get('id')\n            employee_codes = \", \".join(map(str, employee.get('clientCodes', [])))\n            if employee_id:\n                lookup[f\"E_{employee_id}\"] = employee_codes\n    return lookup\n\ndef fetch_survey_data(practice_id, employee_id):\n    # Company ID 0 is typically used for internal surveys\n    url = f\"{BASE_URL}/reviews/practice/{practice_id}/employee/{employee_id}\"\n    params = {\"companyid\": 0, \"fromdate\": FROM_DATE, \"todate\": TO_DATE}\n    response = requests.get(url, auth=auth, params=params)\n    response.raise_for_status()\n    if response.text.strip().upper() == 'NULL' or not response.text.strip():\n        return []\n    return response.json()\n\n# --- UTILITY: Data Flattener ---\ndef flatten_internal_surveys(surveys, practice_id, practice_name, employee_id, employee_name, client_code_lookup):\n    rows = []\n    employee_key = f\"E_{employee_id}\"\n    practice_key = f\"P_{practice_id}\"\n    client_code = client_code_lookup.get(employee_key, \"\") or client_code_lookup.get(practice_key, \"\")\n\n    for survey in surveys:\n        mrn_val = survey.get(\"patientMrn\") or survey.get(\"mrn\") or survey.get(\"MRN\")\n        \n        base_fields = {\n            \"Practice_ID\": practice_id, \n            \"Practice_Name\": practice_name,\n            \"Entity_ID\": employee_id, \n            \"Entity_Name\": employee_name, \n            \"Entity_Type\": \"Employee\",\n            \"Client_Code\": client_code, \n            \"Survey_ID\": survey.get(\"id\"),\n            \"MRN\": mrn_val, \n            \"CompanyId\": survey.get(\"companyId\"), \n            \"CompanyName\": survey.get(\"companyName\"),\n            \"ReviewMonth\": survey.get(\"ReviewMonth\"), \n            \"ReviewDate\": survey.get(\"ReviewDate\"),\n            \"apptLocationCode\": survey.get(\"apptLocationCode\"), \n            \"apptTypeCode\": survey.get(\"apptTypeCode\"),\n            \"apptDeptCode\": survey.get(\"apptDeptCode\"), \n            \"atLoc_rater8Id\": survey.get(\"atLoc_rater8Id\"),\n            \"atLoc_Name\": survey.get(\"atLoc_Name\"),\n        }\n        \n        record_added = False\n        main_rating = survey.get(\"employeeRating\") or survey.get(\"locationRating\")\n        main_comment = survey.get(\"Comment\")\n        \n        if main_rating is not None or (main_comment and main_comment != \"\"):\n            row = base_fields.copy()\n            row.update({\"Question_ID\": 0, \"Question_Name\": \"Employee/Location Main Rating\", \"Rating\": main_rating, \"Comment_Text\": main_comment})\n            rows.append(row)\n            record_added = True\n\n        for q in survey.get(\"questions\", []):\n            row = base_fields.copy()\n            row.update({\"Question_ID\": q.get(\"id\"), \"Question_Name\": q.get(\"name\"), \"Rating\": q.get(\"rating\"), \"Comment_Text\": q.get(\"Comment\")})\n            rows.append(row)\n            record_added = True\n            \n        for cq in survey.get(\"customQuestions\", []):\n            question_type = cq.get(\"questionType\")\n            q_id = CUSTOM_Q_NPS_ID if question_type == \"NPS\" else question_type \n            row = base_fields.copy()\n            row.update({\"Question_ID\": q_id, \"Question_Name\": question_type, \"Rating\": cq.get(\"rating\"), \"Comment_Text\": cq.get(\"comment\")})\n            rows.append(row)\n            record_added = True\n        \n        if not record_added:\n            row = base_fields.copy()\n            row.update({\"Question_ID\": None, \"Question_Name\": \"No Question/Rating Data\", \"Rating\": None, \"Comment_Text\": None})\n            rows.append(row)\n    return rows\n\n# --- SNOWFLAKE UTILITIES ---\n\ndef get_snowflake_conn():\n    return snowflake.connector.connect(\n        user=SF_USER, password=SF_PASSWORD, account=SF_ACCOUNT,\n        warehouse=SF_WAREHOUSE, database=SF_DATABASE, schema=SF_SCHEMA, role=SF_ROLE\n    )\n\ndef map_pandas_dtype_to_snowflake(dtype):\n    if pd.api.types.is_integer_dtype(dtype): return \"NUMBER\"\n    elif pd.api.types.is_float_dtype(dtype): return \"FLOAT\"\n    elif pd.api.types.is_datetime64_any_dtype(dtype): return \"TIMESTAMP_NTZ\"\n    elif pd.api.types.is_bool_dtype(dtype): return \"BOOLEAN\"\n    else: return \"VARCHAR\" \n\ndef create_or_replace_table(conn, df, table_name):\n    cursor = conn.cursor()\n    cols_def = []\n    for col_name, dtype in df.dtypes.items():\n        sf_type = map_pandas_dtype_to_snowflake(dtype)\n        cols_def.append(f'\"{col_name}\" {sf_type}')\n    \n    ddl = f'CREATE OR REPLACE TABLE \"{table_name}\" ({\", \".join(cols_def)})'\n    cursor.execute(ddl)\n    cursor.close()\n\ndef run_merge(conn, target_table, source_table, join_keys):\n    cursor = conn.cursor()\n    cursor.execute(f\"DESC TABLE {source_table}\")\n    columns = [row[0] for row in cursor.fetchall()]\n    \n    on_clause = \" AND \".join([f'target.\"{k}\" = source.\"{k}\"' for k in join_keys])\n    update_clause = \", \".join([f'target.\"{c}\" = source.\"{c}\"' for c in columns])\n    col_list = \", \".join([f'\"{c}\"' for c in columns])\n    val_list = \", \".join([f'source.\"{c}\"' for c in columns])\n    \n    merge_sql = f\"\"\"\n    MERGE INTO \"{target_table}\" AS target\n    USING \"{source_table}\" AS source\n    ON {on_clause}\n    WHEN MATCHED THEN UPDATE SET {update_clause}\n    WHEN NOT MATCHED THEN INSERT ({col_list}) VALUES ({val_list})\n    \"\"\"\n    cursor.execute(merge_sql)\n    cursor.close()\n\ndef upload_to_snowflake_merge(df, table_name, merge_keys):\n    if df.empty:\n        print(f\"⚠️ Skipping Snowflake upload for {table_name}: DataFrame is empty.\")\n        return\n\n    df.columns = [c.upper().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\".\", \"_\") for c in df.columns]\n\n    print(f\"\\n--- Starting Snowflake Merge Operation: {table_name} ---\")\n    try:\n        conn = get_snowflake_conn()\n        cursor = conn.cursor()\n        temp_table_name = f\"{table_name}_TEMP\"\n        \n        create_or_replace_table(conn, df, temp_table_name)\n        write_pandas(conn, df, temp_table_name, auto_create_table=False, quote_identifiers=True)\n        \n        try:\n            cursor.execute(f\"SELECT TOP 1 * FROM \\\"{table_name}\\\"\")\n            table_exists = True\n        except:\n            table_exists = False\n\n        if not table_exists:\n            cursor.execute(f'ALTER TABLE \"{temp_table_name}\" RENAME TO \"{table_name}\"')\n            print(f\"✅ Created {table_name} successfully.\")\n        else:\n            run_merge(conn, table_name, temp_table_name, merge_keys)\n            cursor.execute(f'DROP TABLE IF EXISTS \"{temp_table_name}\"')\n            print(f\"✅ Merge to {table_name} complete.\")\n\n        conn.close()\n    except Exception as e:\n        print(f\"❌ Snowflake Error: {e}\")\n\n# --- MAIN EXECUTION ---\n\ndef main():\n    internal_survey_rows = []\n    \n    print(f\"--- Starting rater8 SURVEY ONLY Pull ({FROM_DATE} to {TO_DATE}) ---\")\n    \n    try:\n        permissions = get_permissions()\n        client_code_lookup = build_client_code_lookup(permissions)\n        total_practices = len(permissions)\n        \n        for p_index, practice in enumerate(permissions):\n            practice_id = practice.get('id')\n            practice_name = practice.get('name', 'N/A')\n            print(f\"Processing Practice {p_index + 1}/{total_practices}: {practice_name}...\")\n\n            for employee in practice.get('employees', []):\n                try:\n                    surveys = fetch_survey_data(practice_id, employee.get('id'))\n                    if surveys:\n                        internal_survey_rows.extend(\n                            flatten_internal_surveys(surveys, practice_id, practice_name, employee.get('id'), employee.get('name'), client_code_lookup)\n                        )\n                except Exception as e:\n                    print(f\"  ❌ Error fetching surveys for {employee.get('name')}: {e}\")\n\n    except Exception as e:\n        print(f\"\\n❌ FATAL ERROR: {e}\")\n        return\n\n    if internal_survey_rows:\n        df_surveys = pd.DataFrame(internal_survey_rows)\n        df_surveys['MRN'] = df_surveys['MRN'].astype(str).replace({'None': None, 'nan': None})\n\n        if 'ReviewDate' in df_surveys.columns: \n            df_surveys['ReviewDate'] = pd.to_datetime(df_surveys['ReviewDate'])\n        \n        upload_to_snowflake_merge(\n            df_surveys, \n            \"RATER8_SURVEYS\", \n            merge_keys=[\"SURVEY_ID\", \"QUESTION_ID\"] \n        )\n    else:\n        print(\"\\n⚠️ No survey data found for the period.\")\n\nif __name__ == \"__main__\":\n    main()",
      "execution_count": null,
      "outputs": []
    }
  ]
}